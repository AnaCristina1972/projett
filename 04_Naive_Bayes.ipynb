{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnaCristina1972/projett/blob/master/04_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "derived-meter",
      "metadata": {
        "id": "derived-meter"
      },
      "source": [
        "# Aula 07 - Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "downtown-tomato",
      "metadata": {
        "id": "downtown-tomato"
      },
      "source": [
        "**Índice**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "impaired-friend",
      "metadata": {
        "id": "impaired-friend"
      },
      "source": [
        "  - [Carregando o conjunto de dados](#Carregando-o-conjunto-de-dados)\n",
        "  - [Naive Bayes \"na mão\"](#Naive-Bayes-\"na-mão\")\n",
        "    - [Probabilidades a priori](#Probabilidades-a-priori)\n",
        "    - [Cálculo das verossimilhanças \"ingênuas\"](#Cálculo-das-verossimilhanças-\"ingênuas\")\n",
        "    - [Classificando um exemplo](#Classificando-um-exemplo)\n",
        "  - [Uma classe para Naive Bayes](#Uma-classe-para-Naive-Bayes)\n",
        "  - [Naive Bayes com o Scikit-Learn](#Naive-Bayes-com-o-Scikit-Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "toxic-logic",
      "metadata": {
        "id": "toxic-logic"
      },
      "source": [
        "## Carregando o conjunto de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "empirical-minimum",
      "metadata": {
        "id": "empirical-minimum"
      },
      "source": [
        "Especifica o diretório onde os dados estão. Melhor usar em todos os *notebooks* para que você possa manter todos  arquivos de dados juntos.\n",
        "\n",
        "Caso a localização dos dados no seu computador seja diferente, troque a variável abaixo. Caso esteja no mesmo diretório (*e.g.*, no Colaboratory), coloque `DIR_DADOS = ./`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "latest-pearl",
      "metadata": {
        "id": "latest-pearl"
      },
      "outputs": [],
      "source": [
        "DIR_DADOS = '../dados/'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "creative-scenario",
      "metadata": {
        "id": "creative-scenario"
      },
      "source": [
        "Comandos iniciando com `!` são executados pelo *shell* do sistema operacional. Por exemplo, a imagem abaixo foi gerada quando o *notebook* foi executado pela última vez, mostrando o conteúdo do diretório `../dados`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "civic-corpus",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "civic-corpus",
        "outputId": "5a6ea796-c0e6-4657-f907-67c4757fb253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '../dados/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls ../dados/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vanilla-afghanistan",
      "metadata": {
        "id": "vanilla-afghanistan"
      },
      "source": [
        "Vamos trabalhar com o conjunto de dados `playtennis`, que está disponibilizado no ColabWeb como um arquivo CSV.\n",
        "\n",
        "O jeito mais fácil de trabalhar arquivos CSV em Python é utilizando o Pandas. Normalmente nós importamos o Pandas dando a ele o apelido `pd`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "political-blanket",
      "metadata": {
        "id": "political-blanket"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thousand-handy",
      "metadata": {
        "id": "thousand-handy"
      },
      "source": [
        "A função `pandas.read_csv` lê o arquivo como CSV em um objeto `pandas.DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "municipal-emerald",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "municipal-emerald",
        "outputId": "e4d84322-c4db-41ca-f435-9a0904a44eed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../dados//content/tennis.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-201b16f0485e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtennis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR_DADOS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/content/tennis.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dados//content/tennis.csv'"
          ]
        }
      ],
      "source": [
        "tennis = pd.read_csv(DIR_DADOS + '/content/tennis.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "foreign-neutral",
      "metadata": {
        "id": "foreign-neutral"
      },
      "outputs": [],
      "source": [
        "type(tennis)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "divine-algorithm",
      "metadata": {
        "id": "divine-algorithm"
      },
      "source": [
        "O *data frame* é uma estrutura de dados que se comporta como uma matriz que contém dois índices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "public-purse",
      "metadata": {
        "id": "public-purse"
      },
      "outputs": [],
      "source": [
        "tennis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "royal-toronto",
      "metadata": {
        "id": "royal-toronto"
      },
      "source": [
        "Eis o índice das colunas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gothic-guide",
      "metadata": {
        "id": "gothic-guide"
      },
      "outputs": [],
      "source": [
        "tennis.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "advance-century",
      "metadata": {
        "id": "advance-century"
      },
      "source": [
        "E o índice das linhas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "handed-habitat",
      "metadata": {
        "id": "handed-habitat"
      },
      "outputs": [],
      "source": [
        "tennis.index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "executive-radius",
      "metadata": {
        "id": "executive-radius"
      },
      "source": [
        "Se você utilizar o operador sobrecarregado `[]`, você pode acessar uma coluna por meio de sua chave no índice. Por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "internal-beaver",
      "metadata": {
        "id": "internal-beaver"
      },
      "outputs": [],
      "source": [
        "tennis['aparencia']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exact-float",
      "metadata": {
        "id": "exact-float"
      },
      "source": [
        "Quando você acessa uma coluna ou uma linha em um *data frame*, o resultado é um objeto da classe `Series`, também do Pandas.\n",
        "\n",
        "Se o *data frame* é uma matriz com dois índices, então a série é um vetor com um único índice. No caso do acesso às colunas, o índice da série é o índice das linhas do *data frame*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "facial-celebration",
      "metadata": {
        "id": "facial-celebration"
      },
      "outputs": [],
      "source": [
        "type(tennis['aparencia'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beneficial-submission",
      "metadata": {
        "id": "beneficial-submission"
      },
      "source": [
        "Além do acesso implícito por meio do operador sobrecarregado `[]`, o `DataFrame` permite acecssar de maneira explícita o índice `iloc`, que é puramente posicional, e o índice `loc`, que usa chaves para encontrar as linhas e as colunas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bulgarian-jefferson",
      "metadata": {
        "id": "bulgarian-jefferson"
      },
      "outputs": [],
      "source": [
        "tennis.loc[3, 'aparencia']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "invalid-vietnam",
      "metadata": {
        "id": "invalid-vietnam"
      },
      "outputs": [],
      "source": [
        "tennis.iloc[0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forbidden-lodge",
      "metadata": {
        "id": "forbidden-lodge"
      },
      "source": [
        "Para vermos os valores únicos, podemos usar o método `drop_duplicates()` do Series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "addressed-precipitation",
      "metadata": {
        "id": "addressed-precipitation"
      },
      "outputs": [],
      "source": [
        "tennis['aparencia'].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "neither-tourist",
      "metadata": {
        "id": "neither-tourist"
      },
      "outputs": [],
      "source": [
        "tennis['aparencia'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unusual-border",
      "metadata": {
        "id": "unusual-border"
      },
      "source": [
        "## Naive Bayes \"na mão\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "latin-solomon",
      "metadata": {
        "id": "latin-solomon"
      },
      "source": [
        "Vamos implementar primeiro o Naive Bayes. Vamos praticar um pouco manipulando o *data frame*. Depois vamos escrever uma classse que faz o treinamento, isto é, que aprende os parâmetros para generalizar os dados passados."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prerequisite-marker",
      "metadata": {
        "id": "prerequisite-marker"
      },
      "source": [
        "### Probabilidades a priori"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "official-lambda",
      "metadata": {
        "id": "official-lambda"
      },
      "source": [
        "Vamos começar calculando as probabilidades priori. Neste momento, vamos fazer isso especificamente para o problema `playtennis`, fazendo uso do conhecimento que existem duas classes.\n",
        "\n",
        "Para calcular as prioris, fazemos a contagem dos exemplos do conjunto de treinamento para estimar as frequências de ambas as classes.\n",
        "\n",
        "Primeiro, separamos os exemplos da classe positiva dos exemplos da classe negativa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surgical-policy",
      "metadata": {
        "id": "surgical-policy"
      },
      "outputs": [],
      "source": [
        "idx_sim = tennis['jogar'] == 'sim'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quick-operation",
      "metadata": {
        "id": "quick-operation"
      },
      "source": [
        "Essa comparação vai produzir uma máscara, um índice de onde se encontram os exemplos da classe positiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mental-delicious",
      "metadata": {
        "id": "mental-delicious"
      },
      "outputs": [],
      "source": [
        "idx_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "synthetic-captain",
      "metadata": {
        "id": "synthetic-captain"
      },
      "source": [
        "Utilizando o operador de negação bit-a-bit, podemos gerar a máscara dos exemplos negativos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "floral-radius",
      "metadata": {
        "id": "floral-radius"
      },
      "outputs": [],
      "source": [
        "idx_nao = ~idx_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scientific-lodging",
      "metadata": {
        "id": "scientific-lodging"
      },
      "outputs": [],
      "source": [
        "idx_nao"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prime-distinction",
      "metadata": {
        "id": "prime-distinction"
      },
      "source": [
        "Agora, aplicando essa máscara no *data frame*, podemos obter apenas as linhas que contém exemplos positivos ou negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mexican-collapse",
      "metadata": {
        "id": "mexican-collapse"
      },
      "outputs": [],
      "source": [
        "exemplos_sim = tennis[idx_sim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "attractive-grammar",
      "metadata": {
        "id": "attractive-grammar"
      },
      "outputs": [],
      "source": [
        "exemplos_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "attempted-proof",
      "metadata": {
        "id": "attempted-proof"
      },
      "source": [
        "As primeiras frequências que precisamos guardar é, portanto, a frequência das duas classes. Ou seja, as probabilidades a priori."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "complimentary-model",
      "metadata": {
        "id": "complimentary-model"
      },
      "outputs": [],
      "source": [
        "exemplos_nao = tennis[idx_nao]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imperial-assist",
      "metadata": {
        "id": "imperial-assist"
      },
      "outputs": [],
      "source": [
        "exemplos_nao"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ideal-difference",
      "metadata": {
        "id": "ideal-difference"
      },
      "source": [
        "Excelente.\n",
        "\n",
        "O próximo passo é calcular os números de exemplos. As classes do Pandas (e também as do NumPy) possuem um atributo chamado `shape` que armazena os tamanhos das dimensões dos objetos.\n",
        "\n",
        "No caso de *data frames*, a propriedade `pandas.DataFrame.shape` é uma tupla com dois valores. O primeiro é o número de linhas e o segundo é o número de colunas. Usaremos essa informação para calcular o número de exemplos de cada classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blond-harris",
      "metadata": {
        "id": "blond-harris"
      },
      "outputs": [],
      "source": [
        "tennis.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verbal-explanation",
      "metadata": {
        "id": "verbal-explanation"
      },
      "outputs": [],
      "source": [
        "num_sim = exemplos_sim.shape[0]\n",
        "num_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "parallel-drive",
      "metadata": {
        "id": "parallel-drive"
      },
      "outputs": [],
      "source": [
        "num_nao = exemplos_nao.shape[0]\n",
        "num_nao"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lasting-fiber",
      "metadata": {
        "id": "lasting-fiber"
      },
      "source": [
        "Vamos criar um dicionário chamado `nb_tennis` no qual iremos guardar todas as probabilidades (prioris e verossimilhanças)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "powered-marble",
      "metadata": {
        "id": "powered-marble"
      },
      "outputs": [],
      "source": [
        "nb_tennis = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tutorial-alabama",
      "metadata": {
        "id": "tutorial-alabama"
      },
      "outputs": [],
      "source": [
        "nb_tennis['sim'] = num_sim / (num_sim + num_nao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "textile-insulin",
      "metadata": {
        "id": "textile-insulin"
      },
      "outputs": [],
      "source": [
        "nb_tennis['nao'] = num_nao / (num_sim + num_nao)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acknowledged-blink",
      "metadata": {
        "id": "acknowledged-blink"
      },
      "outputs": [],
      "source": [
        "nb_tennis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "arbitrary-chemistry",
      "metadata": {
        "id": "arbitrary-chemistry"
      },
      "source": [
        "### Adendo: *list comprehensions*, *lambda*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dimensional-bracket",
      "metadata": {
        "id": "dimensional-bracket"
      },
      "source": [
        "O restante dos cálculos poderia ser feito de duas formas. A primeira é com \"programação tradicional\", usando `for`, iteradores e acumuladores. Mas podemos utilizar recursos de programação funcional do Python para fazer a mesma coisa mais rapidamente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diverse-radical",
      "metadata": {
        "id": "diverse-radical"
      },
      "source": [
        "O primeiro recurso que vamos utilizar aqui é o de função lambda. A função lambda é uma função anônima que pode ser declarada como uma expressão.\n",
        "\n",
        "Uma declaração \"tradicional\" de função é feita com `def`. Nome a sintaxe:\n",
        "\n",
        "    def IDENTIFICADOR(PARAMETROS):\n",
        "        CORPO\n",
        "\n",
        "Quando essa declaração é executada, um nome é definido e associado à função."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loving-pocket",
      "metadata": {
        "id": "loving-pocket"
      },
      "outputs": [],
      "source": [
        "def fsoma(x, y):\n",
        "    return x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "american-brunswick",
      "metadata": {
        "id": "american-brunswick"
      },
      "outputs": [],
      "source": [
        "type(fsoma)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceramic-astrology",
      "metadata": {
        "id": "ceramic-astrology"
      },
      "source": [
        "Se utilizarmos esse nome em uma chamada, a função é executada e o valor retornado é avaliado como a saída da célula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "varied-garden",
      "metadata": {
        "id": "varied-garden"
      },
      "outputs": [],
      "source": [
        "fsoma(4, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "advised-spirit",
      "metadata": {
        "id": "advised-spirit"
      },
      "source": [
        "A mesma função poderia ser definida com expressão lambda. A expressão lambda cria uma função anônima, que podemos referenciar com uma variável.\n",
        "\n",
        "A sintaxe é bem parecida. Compare:\n",
        "\n",
        "```Python\n",
        "def    fsoma(x, y): return x + y\n",
        "lambda       x, y :        x + y\n",
        "```\n",
        "      \n",
        "Essencialmente, a palavra `def` é substituída pela palavra `lambda` e, como a função lambda é anônima, o identificador da função some. Os parênteses na lista de parâmetros são desnecessários. E, como tudo o que uma função lambda pode fazer é executar um único comando `return`, a palavra `return` também é desnecessária.\n",
        "\n",
        "Para não perdermos acesso à função anônima, iremos referenciá-la com uma variável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "saved-republic",
      "metadata": {
        "id": "saved-republic"
      },
      "outputs": [],
      "source": [
        "lsoma = lambda x, y: x + y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "decent-majority",
      "metadata": {
        "id": "decent-majority"
      },
      "source": [
        "Essa variável pode ser utilizada do mesmo jeito que o identificador de funções é utilizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "freelance-survival",
      "metadata": {
        "id": "freelance-survival"
      },
      "outputs": [],
      "source": [
        "lsoma(4, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pressed-keyboard",
      "metadata": {
        "id": "pressed-keyboard"
      },
      "source": [
        "O segundo recurso que vamos utilizar aqui é o de *list comprehension* ou compreensão de listas. A compreensão de lsitas permite declarar listas com uma notação semelhante à que utilizamos na matemática para descrever conjuntos implícitos.\n",
        "\n",
        "Por exemplo, o conjunto de todos os números quadrados no intervalo $[0,10]$ pode ser descrito da seguinte forma:\n",
        "\n",
        "$$\\{x^2 | 0 \\leq x \\leq 10 \\wedge x \\in \\mathbb{Z}\\}$$\n",
        "\n",
        "Em Python, uma lista com esses valores poderia ser escrita da seguinte maneira:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "damaged-plain",
      "metadata": {
        "id": "damaged-plain"
      },
      "outputs": [],
      "source": [
        "[x**2 for x in range(11)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "joined-methodology",
      "metadata": {
        "id": "joined-methodology"
      },
      "source": [
        "A notação é:\n",
        "\n",
        "```Python\n",
        "[EXPRESSAO for VARIAVEL in CONJUNTO]\n",
        "```\n",
        "\n",
        "Nesse caso, `range(11)` sozinho já especifica ao mesmo tempo que todos os valores estão no intervalo $[0, 10]$ e também que são números inteiros.\n",
        "\n",
        "Na compreensão de listas também podemos especificar uma condição. Por exemplo, se quisermos todos os números pares entre 0 e 10, a notação matemática é:\n",
        "\n",
        "$$\\{x | 0 \\leq x \\leq 100 \\wedge x \\in \\mathbb{Z} \\wedge x \\equiv 0 (\\text{mod } 2)\\}$$\n",
        "\n",
        "Em Python, as condições da compreensão de listas podem ser especificadas com um `if`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "arctic-suggestion",
      "metadata": {
        "id": "arctic-suggestion"
      },
      "outputs": [],
      "source": [
        "[x for x in range(11) if x % 2 == 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ready-columbus",
      "metadata": {
        "id": "ready-columbus"
      },
      "source": [
        "No restante do *notebook*, vamos ver os comandos com compreensão de listas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "disabled-shepherd",
      "metadata": {
        "id": "disabled-shepherd"
      },
      "source": [
        "### Cálculo das verossimilhanças \"ingênuas\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "political-upper",
      "metadata": {
        "id": "political-upper"
      },
      "source": [
        "Agora vamos calcular as verossimilhanças. Para isso, faremos uso do método `value_counts()`, que retorna uma contagem de cada valor de uma série.\n",
        "\n",
        "Por exemplo, se quisermos saber quantas vezes cada valor de aparência aparece na coluna `aparencia`, podemos fazer o seguinte:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interior-newfoundland",
      "metadata": {
        "id": "interior-newfoundland"
      },
      "outputs": [],
      "source": [
        "tennis['aparencia'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "municipal-entertainment",
      "metadata": {
        "id": "municipal-entertainment"
      },
      "source": [
        "Se fizermos isso apenas para os exemplos da classe positiva e depois dividirmos pelo número de exemplos dessa classe, o resultado será $p(\\textsf{aparencia}=x_i|\\textsf{sim})$ para cada valor $x_i$ do atributo `aparencia`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "under-consumer",
      "metadata": {
        "id": "under-consumer"
      },
      "outputs": [],
      "source": [
        "exemplos_sim['aparencia'].value_counts() / num_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "architectural-pharmacology",
      "metadata": {
        "id": "architectural-pharmacology"
      },
      "source": [
        "Fascinante!\n",
        "\n",
        "Então, vamos fazer a mesma coisa para todos os atributos. Primeiro, vamos declarar uma lista que contém todos os nomes dos atributos. Essa lista vai nos ajudar a montar a compreensão de lista depois."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "knowing-mauritius",
      "metadata": {
        "id": "knowing-mauritius"
      },
      "outputs": [],
      "source": [
        "atributos = ['aparencia', 'temperatura', 'umidade', 'vento']\n",
        "atributos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "governmental-brief",
      "metadata": {
        "id": "governmental-brief"
      },
      "source": [
        "Veja que é bem semelhante ao exemplo anterior. Se tivermos uma compreensão `[EXPRESSÃO for VAR in atributos]`, então a lista será construída com base na expressão para cada valor da lista `atributos`.\n",
        "\n",
        "Se a expressão for simplesmente o nome da variável, então o resultado será uma cópia da lista original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worthy-grass",
      "metadata": {
        "id": "worthy-grass"
      },
      "outputs": [],
      "source": [
        "[X for X in atributos]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "verbal-newcastle",
      "metadata": {
        "id": "verbal-newcastle"
      },
      "source": [
        "Mas podemos usar a variável em algumas expressões mais interessantes. Por exemplo, se fizermos `len(X)`, então o resultado será uma lista equivalente à seguinte:\n",
        "\n",
        "```Python\n",
        "[len(atributos[0]), len(atributos[1]), len(atributos[2]), len(atributos[3])]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bronze-optics",
      "metadata": {
        "id": "bronze-optics"
      },
      "outputs": [],
      "source": [
        "[len(X) for X in atributos]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "white-senegal",
      "metadata": {
        "id": "white-senegal"
      },
      "source": [
        "Da mesma maneira, podemos usar `X` em uma expressão que obtém as verossimilhanças:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "decent-polls",
      "metadata": {
        "id": "decent-polls"
      },
      "outputs": [],
      "source": [
        "freq_sim = [exemplos_sim[X].value_counts() / num_sim for X in atributos]\n",
        "freq_sim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "portable-anger",
      "metadata": {
        "id": "portable-anger"
      },
      "source": [
        "Esse código seria equivalente ao seguinte:\n",
        "\n",
        "```Python\n",
        "# Cria uma lista com o tamanho certo e valores iniciais quaiser\n",
        "freq_sim = []\n",
        "for X in atributos:\n",
        "    freq_sim.append(exemplos_sim[X].value_counts() / num_sim)\n",
        "```\n",
        "\n",
        "Note como a compreensão de listas é be mais expressiva. Além disso, em muitas situações ela pode ser bem mais eficiente. Por exemplo, na compreensão de lista o tamanho da lista não muda com cada iteração do laço `for`.\n",
        "\n",
        "Agora fazemos o mesmo para a verossimilhanças da classe negativa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "inappropriate-evidence",
      "metadata": {
        "id": "inappropriate-evidence"
      },
      "outputs": [],
      "source": [
        "freq_nao = [tennis[idx_nao][X].value_counts() / num_nao for X in atributos]\n",
        "freq_nao"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "perceived-fifteen",
      "metadata": {
        "id": "perceived-fifteen"
      },
      "source": [
        "E finalmente guardamos o resultado no dicionário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "individual-jenny",
      "metadata": {
        "id": "individual-jenny"
      },
      "outputs": [],
      "source": [
        "nb_tennis['vsim'] = freq_sim\n",
        "nb_tennis['vnao'] = freq_nao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alike-premises",
      "metadata": {
        "id": "alike-premises"
      },
      "outputs": [],
      "source": [
        "nb_tennis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "circular-budget",
      "metadata": {
        "id": "circular-budget"
      },
      "source": [
        "### Classificando um exemplo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lyric-hollow",
      "metadata": {
        "id": "lyric-hollow"
      },
      "source": [
        "Agora vamos pensar no código que realiza a classificação. Para simplificar, vamos supor que o exemplo a ser classificado está numa série do Pandas.\n",
        "\n",
        "Então vamos começar recriando o exemplo do dia 15 que vimos em aula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "talented-theme",
      "metadata": {
        "id": "talented-theme"
      },
      "outputs": [],
      "source": [
        "atributos = ['ensolarado', 'moderado', 'alta', 'forte']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "signal-courage",
      "metadata": {
        "id": "signal-courage"
      },
      "outputs": [],
      "source": [
        "valores = ['aparencia', 'temperatura', 'umidade', 'vento']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "express-trustee",
      "metadata": {
        "id": "express-trustee"
      },
      "outputs": [],
      "source": [
        "exemplo = pd.Series(atributos, valores)\n",
        "exemplo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ranging-devices",
      "metadata": {
        "id": "ranging-devices"
      },
      "source": [
        "Para classificar esse exemplo, precisamos descobrir se $p(\\textsf{sim}|x)$ é maior que $p(\\textsf{não}|x)$ ou o contrário. Isso significa estimar os valores proporcionais a eles multiplicando as verossimilhanças pelas prioris.\n",
        "\n",
        "No dicionário que criamos, `nb_tennis['vsim']` é uma lista que contém todas as verossimilhanças de cada exemplo. O primeiro elemento dessa lista é o conjunto das verossimilhanças $p(\\textsf{aparencia}=x_i|\\textsf{sim})$. Se indexarmos essa lista pelo valor que o exemplo possui para o atributo `aparencia`, o resultado será $p(\\textsf{ensolarado}|\\textsf{sim})$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "swiss-exposure",
      "metadata": {
        "id": "swiss-exposure"
      },
      "outputs": [],
      "source": [
        "nb_tennis['vsim'][0]['ensolarado']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suited-gnome",
      "metadata": {
        "id": "suited-gnome"
      },
      "source": [
        "Ou:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "proprietary-leather",
      "metadata": {
        "id": "proprietary-leather"
      },
      "outputs": [],
      "source": [
        "nb_tennis['vsim'][0][exemplo[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stuffed-soundtrack",
      "metadata": {
        "id": "stuffed-soundtrack"
      },
      "source": [
        "Se empregarmos isso em uma compreensão de lista, o resultado será o conjunto de todas as verossimilhanças que procuramos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "certified-silicon",
      "metadata": {
        "id": "certified-silicon"
      },
      "outputs": [],
      "source": [
        "[nb_tennis['vsim'][X][exemplo[X]] for X in range(4)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recorded-granny",
      "metadata": {
        "id": "recorded-granny"
      },
      "source": [
        "Essa compreensão é equivalente à seguinte iteração:\n",
        "\n",
        "```Python\n",
        "l = []\n",
        "for X in range(4):\n",
        "    l.append(nb_tennis['vsim'][X][exemplo[X]])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "modern-combine",
      "metadata": {
        "id": "modern-combine"
      },
      "source": [
        "Agora podemos fazer uso do NumPy para multiplicar todos esses valores. A função `numpy.prod()` recebe como entra uma coleção que pode ser um vetor, uma matriz, um *data frame* ou semelhante, e retorna o produto de todos os elementos dessa coleção.\n",
        "\n",
        "Por exemplo, o produto de `2 * 3 * 4 * 5` é 120:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dying-apple",
      "metadata": {
        "id": "dying-apple"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "present-appliance",
      "metadata": {
        "id": "present-appliance"
      },
      "outputs": [],
      "source": [
        "np.prod([2, 3, 4, 5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "literary-calcium",
      "metadata": {
        "id": "literary-calcium"
      },
      "source": [
        "Usamos `np.prod` para multiplicar todas as verossimilhanças e depois multiplicamos pela priori de cada classe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spoken-primary",
      "metadata": {
        "id": "spoken-primary"
      },
      "outputs": [],
      "source": [
        "np.prod([nb_tennis['vsim'][X][exemplo[X]] for X in range(4)]) * nb_tennis['sim']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rapid-kitty",
      "metadata": {
        "id": "rapid-kitty"
      },
      "source": [
        "Esse código é equivalente ao seguinte:\n",
        "\n",
        "```Python\n",
        "prod = 1\n",
        "for X in range(4):\n",
        "    prod *= nb_tennis['vsim'][X][exemplo[X]]\n",
        "prod *= nb_tennis['sim']\n",
        "prod\n",
        "```\n",
        "\n",
        "E fazemos o mesmo para a classe negativa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ruled-complex",
      "metadata": {
        "id": "ruled-complex"
      },
      "outputs": [],
      "source": [
        "np.prod([nb_tennis['vnao'][X][exemplo[X]] for X in range(4)]) * nb_tennis['nao']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fiscal-hierarchy",
      "metadata": {
        "id": "fiscal-hierarchy"
      },
      "source": [
        "Como você pode ver, isso nos levaria à decisão de que a classe positiva é a mais provável, assim como concluímos com os exemplos dos slides."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "classical-diploma",
      "metadata": {
        "id": "classical-diploma"
      },
      "source": [
        "## Uma classe para Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brazilian-acceptance",
      "metadata": {
        "id": "brazilian-acceptance"
      },
      "source": [
        "Agora podemos juntar tudo em uma classe. Ela tem o método `fit` para, assim como os modelos do Scikit, aprender os parâmetros do modelo para um conjunto de treinamento. E tem também o método `predict`, que faz inferência. Diferentemente do Scikit, nossa classe só faz inferência em um exemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "falling-canberra",
      "metadata": {
        "id": "falling-canberra"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self._prioris = {}\n",
        "        self._likelihoods = {}\n",
        "\n",
        "        self._labels = []\n",
        "        self._num_labels = -1\n",
        "\n",
        "        self._features = []\n",
        "        self._num_features = -1\n",
        "\n",
        "    def _estimate_frequencies(self, series):\n",
        "        return series.value_counts() / series.shape[0]\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self._labels = list(y.drop_duplicates())\n",
        "        self._features = X.keys().values\n",
        "\n",
        "        self._num_features = X.shape[1]\n",
        "        self._num_labels = len(self._labels)\n",
        "\n",
        "        self._prioris = self._estimate_frequencies(y)\n",
        "        for label in self._labels:\n",
        "            subset = X[y == label]\n",
        "            self._likelihoods[label] = [self._estimate_frequencies(subset[X]) for X in self._features]\n",
        "\n",
        "    def _get_likelihood(self, feature, value, label):\n",
        "        return self._likelihoods[label][feature][value]\n",
        "\n",
        "    def predict(self, Xpred):\n",
        "        ypred = None\n",
        "        ypred_chance = -1\n",
        "\n",
        "        chance_sum = 0\n",
        "        prob = np.zeros((self._num_labels,), dtype=np.float64)\n",
        "\n",
        "        for l in range(self._num_labels):\n",
        "            label = self._labels[l]\n",
        "            this_priori = self._prioris[label]\n",
        "            this_chance = np.prod([self._get_likelihood(X, Xpred[X], label) for X in range(4)]) * this_priori\n",
        "\n",
        "            prob[l] = this_chance\n",
        "            chance_sum += this_chance\n",
        "\n",
        "            if this_chance > ypred_chance:\n",
        "                ypred = label\n",
        "                ypred_chance = this_chance\n",
        "\n",
        "        prob /= chance_sum\n",
        "        return (ypred, prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dangerous-stretch",
      "metadata": {
        "id": "dangerous-stretch"
      },
      "source": [
        "Para treinar, primeiro separamos os dados em atributos e rótulos.\n",
        "\n",
        "Para a nossa classe, é imperativo que os dados estejam em um `DataFrame`  e os rótulos estejam em um `Series`. O Scikit não é tão exigente, apenas requer matrizes para as características e veteores para os rótulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "binding-arrow",
      "metadata": {
        "id": "binding-arrow"
      },
      "outputs": [],
      "source": [
        "X = tennis.iloc[:, :-1]\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spectacular-technical",
      "metadata": {
        "id": "spectacular-technical"
      },
      "outputs": [],
      "source": [
        "y = tennis.iloc[:, -1]\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "devoted-cable",
      "metadata": {
        "id": "devoted-cable"
      },
      "source": [
        "Agora, assim como no Scikit, usamos o método `fit` para aprender os parâmetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contemporary-fourth",
      "metadata": {
        "id": "contemporary-fourth"
      },
      "outputs": [],
      "source": [
        "nb = NaiveBayes()\n",
        "nb.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "boolean-thickness",
      "metadata": {
        "id": "boolean-thickness"
      },
      "source": [
        "Mostre os parâmetros aprendidos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "conservative-berlin",
      "metadata": {
        "id": "conservative-berlin"
      },
      "outputs": [],
      "source": [
        "nb._prioris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "powered-blade",
      "metadata": {
        "id": "powered-blade"
      },
      "outputs": [],
      "source": [
        "nb._likelihoods"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "starting-yacht",
      "metadata": {
        "id": "starting-yacht"
      },
      "source": [
        "Faça predição do exemplo e veja o resultado e as probabilidades **estimadas**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pediatric-pencil",
      "metadata": {
        "id": "pediatric-pencil"
      },
      "outputs": [],
      "source": [
        "exemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "certain-trance",
      "metadata": {
        "id": "certain-trance"
      },
      "outputs": [],
      "source": [
        "nb.predict(exemplo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "green-pursuit",
      "metadata": {
        "id": "green-pursuit"
      },
      "source": [
        "## Naive Bayes com o Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "spoken-creator",
      "metadata": {
        "id": "spoken-creator"
      },
      "source": [
        "Agora, vamos utilizar o Naive Bayes categórico do ScikitLearn.\n",
        "\n",
        "Antes de começar, vamos importar novamente os dados para que as manipulações da seção anterior não nos atrapalhem. Vamos separar as características em uma matriz X e os rótulos em um vetor y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "timely-pierce",
      "metadata": {
        "id": "timely-pierce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d23b1885",
      "metadata": {
        "id": "d23b1885"
      },
      "source": [
        "Carregue os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "crude-meaning",
      "metadata": {
        "id": "crude-meaning"
      },
      "outputs": [],
      "source": [
        "tennis = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a1f441",
      "metadata": {
        "id": "b7a1f441"
      },
      "source": [
        "Separe os dados em `X` (data frame/matriz) e `y` (série/vetor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e9d34c",
      "metadata": {
        "id": "79e9d34c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52fb75de",
      "metadata": {
        "id": "52fb75de"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0d7d73",
      "metadata": {
        "id": "5a0d7d73"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "clean-terminal",
      "metadata": {
        "id": "clean-terminal"
      },
      "source": [
        "O scikit-learn implementa diferentes modelos de classificação baseados em probabilidades no módulo `sklearn.naive_bayes`. Eles se diferem pela forma como calculam as probabilidades dos atributos.\n",
        "\n",
        "O Naive Bayes categórico é implementado pela classe `sklearn.naive_bayes.CategoricalNB`. Por exemplo, para estimar a verossimilhança, ele usa a seguinte fórmula,\n",
        "\n",
        "$$p(x|y) = \\frac{N_x+\\alpha}{N_y+\\alpha{}n_i},$$\n",
        "\n",
        "na qual as variáveis representam o seguinte:\n",
        "\n",
        "- $N_x$ é o número de exemplos da classe $y$ que possuem o valor $x$ para o atributo em questão;\n",
        "- $N_y$ é o número de exemplos da classe $y$;\n",
        "- $\\alpha$ é um fator de ajuste;\n",
        "- $n_i$ é o número de valores distintos que o atributo em questão pode assumir.\n",
        "\n",
        "Tomando o conjunto `play_tennis` como exemplo, tínhamos o seguinte:\n",
        "\n",
        "- Havia 9 instâncias da classe `sim` no conjunto de treinamento;\n",
        "- O atributo `aparencia` possuía três possíveis valores: `ensolarado`, `nublado` e `chuvoso`;\n",
        "- Das 9 instâncias da classe `sim`, duas possuem valor `ensolarado`.\n",
        "\n",
        "Nesse caso, a verossimilhança do valor `ensolarado` seria calculada da seguinte maneira:\n",
        "\n",
        "$$p(\\textsf{ensolarado}|\\textsf{sim})=\\frac{2+\\alpha}{9+3\\alpha}$$\n",
        "\n",
        "Isso se chama suavização de Laplace e serve para resolver problemas que podem acontecer quando um exemplo possui um valor que não estava presente no conjunto de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "attached-moderator",
      "metadata": {
        "id": "attached-moderator"
      },
      "source": [
        "Vamos começar importando esta classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acute-panama",
      "metadata": {
        "id": "acute-panama"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import CategoricalNB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suitable-halloween",
      "metadata": {
        "id": "suitable-halloween"
      },
      "source": [
        "Como no problema `play_tennis` todas as categorias ocorrem para todos os exemplos pelo menos uma vez, não há possibilidade de um exemplo de inferência conter valores novos. Portanto podemos especificar um valor bem pequeno para esse hiperparâmetro—por exemplo, $\\alpha=1\\times10^{-10}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "identified-premises",
      "metadata": {
        "id": "identified-premises"
      },
      "outputs": [],
      "source": [
        "nb = CategoricalNB(alpha=1e-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "technological-opening",
      "metadata": {
        "id": "technological-opening"
      },
      "source": [
        "Entretanto, se tentarmos treinar o classificador Naive Bayes com o  conjunto de atributos que selecionamos, uma exceção será lançada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "resistant-pursuit",
      "metadata": {
        "id": "resistant-pursuit"
      },
      "outputs": [],
      "source": [
        "nb.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fabulous-egypt",
      "metadata": {
        "id": "fabulous-egypt"
      },
      "source": [
        "De modo geral, todos os indutores do Scikit-Learn exigem que os atributos sejam numéricos. Neste caso em que os atributos são categóricos, eles precisam ser mapeados para um conjunto de valores numéricos e discretos.\n",
        "\n",
        "Isso pode ser feito, por exemplo, com a classe `OrdinalEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "annual-encoding",
      "metadata": {
        "id": "annual-encoding"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "falling-bonus",
      "metadata": {
        "id": "falling-bonus"
      },
      "source": [
        "Vamos começar criando um codificador para as características armazenadas em `X`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8a11ae6",
      "metadata": {
        "id": "e8a11ae6"
      },
      "source": [
        "Instancie um objeto da calsse `OrdinalEncoder` e \"treine-o\" nos dados de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "composed-relation",
      "metadata": {
        "id": "composed-relation"
      },
      "outputs": [],
      "source": [
        "tennis_oe ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exotic-probability",
      "metadata": {
        "id": "exotic-probability"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "stretch-constitutional",
      "metadata": {
        "id": "stretch-constitutional"
      },
      "source": [
        "Agora, aplique a transformação aos exemplos originais, produzindo uma nova versão da matriz `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "recovered-airplane",
      "metadata": {
        "id": "recovered-airplane"
      },
      "outputs": [],
      "source": [
        "Xenc = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brilliant-prophet",
      "metadata": {
        "id": "brilliant-prophet"
      },
      "source": [
        "Precisamos fazer a mesma coisa para os rótulos. Entretanto, a classe `OrdinalEncoder` só trabalha com matrizes e `DataFrames`. Para discretizar uma série ou um vetor, usamos a classe `LabelEncoder`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bigger-webmaster",
      "metadata": {
        "id": "bigger-webmaster"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sacred-passage",
      "metadata": {
        "id": "sacred-passage"
      },
      "outputs": [],
      "source": [
        "tennis_le ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "useful-dating",
      "metadata": {
        "id": "useful-dating"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "approximate-former",
      "metadata": {
        "id": "approximate-former"
      },
      "outputs": [],
      "source": [
        "yenc ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "standard-paste",
      "metadata": {
        "id": "standard-paste"
      },
      "source": [
        "Para treinar o modelo, basta usar o método `fit` sobre os exemplos de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "scheduled-chess",
      "metadata": {
        "id": "scheduled-chess"
      },
      "outputs": [],
      "source": [
        "nb.fit(Xenc, yenc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entitled-semiconductor",
      "metadata": {
        "id": "entitled-semiconductor"
      },
      "source": [
        "Vamos testar com o exemplo do dia 15."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "frequent-planet",
      "metadata": {
        "id": "frequent-planet"
      },
      "outputs": [],
      "source": [
        "dia15 = ['ensolarado', 'moderado', 'alta', 'forte']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fatal-franchise",
      "metadata": {
        "id": "fatal-franchise"
      },
      "outputs": [],
      "source": [
        "dia15"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incomplete-issue",
      "metadata": {
        "id": "incomplete-issue"
      },
      "source": [
        "Para codificar esse exemplo em valores ordinais, ele precisa estar contido em uma matriz ou um *data frame*. Basta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beautiful-background",
      "metadata": {
        "id": "beautiful-background"
      },
      "outputs": [],
      "source": [
        "Xteste ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rational-trout",
      "metadata": {
        "id": "rational-trout"
      },
      "source": [
        "E agora usamos o método `predict()` para classificar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "existing-ecology",
      "metadata": {
        "id": "existing-ecology"
      },
      "outputs": [],
      "source": [
        "nb.predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flush-database",
      "metadata": {
        "id": "flush-database"
      },
      "source": [
        "Para nos certificarmos de que ele previu a classe como esperado, usamos o `LabelEncoder` com uma transformação inversa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "portable-shade",
      "metadata": {
        "id": "portable-shade"
      },
      "outputs": [],
      "source": [
        "tennis_le.inverse_transform()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}